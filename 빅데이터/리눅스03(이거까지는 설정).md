

## 프로그램 설치

1. hadoop설치

- 윈도우에서 setup이용하는거랑 똑같은 방법으로 다운로드 받기
  - firefox들어가기 -> java.sun.com/j2se 로 접속 -> top download에서 java se클릭 -> 맨아래 java archive링크 클릭 -> java SE 8(8u211 and later)접속 ->  

![image-20200213094922014](images/image-20200213094922014.png)

![image-20200213095255548](images/image-20200213095255548.png)

![image-20200213095326930](images/image-20200213095326930.png)

- jdk설치

![image-20200213101321530](images/image-20200213101321530.png)

- remote system 사용방법
  - ![image-20200213101544458](images/image-20200213101544458.png)

![image-20200213101935029](images/image-20200213101935029.png)

- hadoop01에 복사된거 확인 가능

![image-20200213102126459](images/image-20200213102126459.png)

- usr에서 root로 옮기기

![image-20200213102306808](images/image-20200213102306808.png)

- jdk-8u2310linux-x64 우클릭 -> 속성 -> 권한 -> 아래 사진 확인

![image-20200213102517769](images/image-20200213102517769.png)

- 다운로드 받고 프로그램 설치할 때 쓰는 명령어 = rpm
  - 의존모듈 없으면 다운로드 못받음
  - 의존모듈을 같이 다운로드 받지 않기 때문에 rpm으로 다운받으면 실행이 안됨.

```
rpm -Uvh jdk-8u231-linux-x64.rpm 
-U => 업데이트 하면서 설치하겠다.
v => view (설치하는 과정을 보겠다.)
h => 설치될때 설치되는 과정을 #으로 보여주겠다.
```

![image-20200213103025112](images/image-20200213103025112.png)



- usr -> java에 아래처럼 설치됨.
  - 이제 hadoop02,03,04에도 설치해주면 됨.

![image-20200213103331825](images/image-20200213103331825.png)

- hadoop01에서 02,03,04에도 설치하기
  - 비밀번호는 모두 bigdata

```
scp /root/jdk-8u231-linux-x64.rpm root@hadoop02:/root/
---------hadoop02의 c드라이브 안의 root에 jdk파일 설치 --------

ssh hadoop02 "rpm - Uvh jdk-8u231-linux-x64.rpm"
---------- hadoop02에 설치한 jdk파일을 실행 ------------------
```

![image-20200213104527577](images/image-20200213104527577.png)

- hadoop02에도 설치가 되었음

![image-20200213104908840](images/image-20200213104908840.png)



- 지금까지처럼 설치파일 말고 압축파일로 받는 방법
  - firefox에서 apache.org접속

![image-20200213110953405](images/image-20200213110953405.png)

- 맨 아래에 Hadoop클릭

![image-20200213111038174](images/image-20200213111038174.png)

- Download 클릭

![image-20200213111254253](images/image-20200213111254253.png)

- hadoop-1.2.1/ 클릭

![image-20200213111324404](images/image-20200213111324404.png)

- 아래사진거 클릭

![image-20200213111431775](images/image-20200213111431775.png)

![image-20200213111512317](images/image-20200213111512317.png)

![image-20200213111533172](images/image-20200213111533172.png)

- 하둡을 실행하고 테스트하는 계정으로 하둡계정을 만들었었다. 
  - root권한이 유지되어있기 때문에 수정해줘야한다. 터미널에서 파일을 카피해서 hadoop권한으로 바꿔줘야 한다.

![image-20200213112215204](images/image-20200213112215204.png)

- 우선 다운로드에 있는 위 파일을 홈으로 옮기기

![image-20200213112251973](images/image-20200213112251973.png)

- 카피

![image-20200213111920325](images/image-20200213111920325.png)

- 하둡의 ~(home)에 들어가서 잘 카피 되었는지 확인해보기

![image-20200213112125142](images/image-20200213112125142.png)

- 소유자가 root가 아니라 hadoop으로 변경되어 있음

![image-20200213112021229](images/image-20200213112021229.png)

- 지금까지 자바랑 하둡 다운받고 설치 한거임
  - rpm은 설치파일
    - usr폴더 = 윈도우에서 program files
  - tar.gz은 압축파일



- 압축풀기

![image-20200213113023875](images/image-20200213113023875.png)

- 여기서 -zxvf에서의 순서는 바뀌어도 상관없다.

  

- 아래에 압축이 풀어짐.

![image-20200213113232748](images/image-20200213113232748.png)

- hadoop02,03,04의 home의 hadoop폴더에 복사

![image-20200213113549883](images/image-20200213113549883.png)

- hadoop01에서 02,03,04의 파일들 압축 풀기

![image-20200213113819045](images/image-20200213113819045.png)

![image-20200213114138195](images/image-20200213114138195.png)



- bin폴더
  - 실행파일들이 모여있음.

- jar폴더
  - 하둡이 사용하고 있는 라이브러리들을 모아놓은 곳
- conf폴더
  - 설정파일들이 모여있는 곳.

![image-20200213114311292](images/image-20200213114311292.png)



### 하둡 설정파일 등록하기

- conf폴더에 있는 설정 파일들 수정하기.

![image-20200213132613089](images/image-20200213132613089.png)

![image-20200213132744237](images/image-20200213132744237.png)

- 아래 사진의 이름 카피

![image-20200213132919659](images/image-20200213132919659.png)

- 아래처럼 주석문 지워주고 export행을 수정해주자
  - 하둡이 자바를 쓰는데 경로를 알려줘야 자바를 쓰든지 말든 하지.

![image-20200213133028577](images/image-20200213133028577.png)

- masters
  - localhost를 지워주고 secondary namenode로 이름을 설정해주자

![image-20200213133200251](images/image-20200213133200251.png)

![image-20200213133222580](images/image-20200213133222580.png)

- slaves
  - datanode와 task tracker

![image-20200213133345458](images/image-20200213133345458.png)

![image-20200213133405812](images/image-20200213133405812.png)

- hadoop권한으로 임시 디렉토리 만들기
  - HDFS에 저장하는 파일내용이 hadoop-data에 저장될 것임.

![image-20200213133751961](images/image-20200213133751961.png)

![image-20200213133803138](images/image-20200213133803138.png)

![image-20200213134225511](images/image-20200213134225511.png)

![image-20200213134249058](images/image-20200213134249058.png)

![image-20200213133954379](images/image-20200213133954379.png)

![image-20200213134156418](images/image-20200213134156418.png)

![image-20200213135155766](images/image-20200213135155766.png)

- hdfs-site를 geditor로 열기

![image-20200213141412942](images/image-20200213141412942.png)

- dfs.replication = 복제본의 갯수
  - 복제본을 저장할 꺼고 블록단위를 3개씩 저장할 꺼다

- dfs.http.address , dfs.secondary.http.address
  - namenode와 secondary노드의 정보임. 
    - 서로 통신해야하니까.

![image-20200213142101347](images/image-20200213142101347.png)



![image-20200213135222357](images/image-20200213135222357.png)

![image-20200213142405623](images/image-20200213142405623.png)



![image-20200213135251412](images/image-20200213135251412.png)

- hadoop01파일을 hadoop02에 복사

![image-20200213143503150](images/image-20200213143503150.png)



- namenode 포맷할 거임

```
/home/hadoop/hadoop-1.2.1/bin/hadoop namenode -format
```

![image-20200213144139312](images/image-20200213144139312.png)

- 하둡 실행하기

  - start-all(하둡을 실행. 가상머신 4대를 한대처럼 묶어서 실행하려고 02,03,04에다가 역할을 분담한것.)
    - 컴퓨터 끌때 stop-all해주기. (서버를 꺼줘야 하니까.)

  - jps = 자바 프로세스를 확인하기
    - hadoop02,03,04의 역할을 확인하기.

![image-20200213144952901](images/image-20200213144952901.png)

![image-20200213145047872](images/image-20200213145047872.png)



- 머신 종료하는 방법
  - power off를 하든 일시정지를 하든 우리는 데스크 탑을 끌꺼니까 반드시 stop-all을 해줘야함

```
02,03,04에다가 역할을 분담한것.
```

![image-20200213150610247](images/image-20200213150610247.png)



- 파일을 하둡의 HDFS에 저장하기

  - 우선 하둡 홈에 들어가자

    cd hadoop-1.2.1/

    ```
    ./bin/hadoop fs
    현재폴더에 있는 bin폴더의 hadoop명령어를 쓸꺼다.
    ```

    ```
    ./bin/hadoop fs -mkdir /input
    하둡 명령어를 써서 input폴더를 만들기
    ```

    ```
    ./bin/hadoop fs -copyFromLocal README.txt /input
    EADME.txt.를 방금 만든 input폴더에 저장할 거다.
    ```



- 분산되어서 저장되는 것 확인
  - 아래 사진의 사이트는 namenode관리자 페이지임

![image-20200213160610449](images/image-20200213160610449.png)









![image-20200213160631330](images/image-20200213160631330.png)

![image-20200213161016379](images/image-20200213161016379.png)

![image-20200213161041108](images/image-20200213161041108.png)

![image-20200213161110076](images/image-20200213161110076.png)